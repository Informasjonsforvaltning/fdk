######### Input #########
input {
  file {
    path => "/tmp/spring.log"
    # having start_position set to beginning will ensure we parse the entire log file - useful for debugging
    start_position => "beginning"
    # setting sincedb_path to /dev/null will ensure we always parse logs fresh every time - useful for debugging
    #sincedb_path => "/dev/null"
  }
}
######### Input #########

######### Filter #########
filter {
  # Extract event severity, timestamp and logevent type
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:severity}.+?([a-zA-Z]+\.)+.+?- \[%{WORD:logger}\] \[%{WORD:result}\] %{GREEDYDATA:rawContent}" }
      tag_on_failure => [ "validation" ]
  }
  if "validation" in [tags] {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:severity}.+?\[%{DATA:result}\].+?ValidationError\{%{GREEDYDATA:content}" }
      add_field => { "logger" => "crawler_operations" }
      tag_on_failure => [ "fail" ]
    }
  } else {
    if "ERROR" in [severity] {
      grok {
        match => { "rawContent" => "%{DATA:event}: %{GREEDYDATA:content}.+?error=%{GREEDYDATA:cause}" }
        tag_on_failure => [ "fail" ]
      }
    } else {
      grok {
        match => { "rawContent" => "%{DATA:event}: %{GREEDYDATA:content}" }
        tag_on_failure => [ "fail" ]
      }
    }
  }

  kv {
    source => "content"
    field_split => ", "
    value_split => "="
    include_keys => [ "crawler_id", "crawler_name", "crawler_url", "user_id", "user_name", "ruleId", "ruleDescription", "ruleSeverity" ]
  }
  mutate {
    remove_field => [ "content, rawContent, logger" ]
  }
  if "validation" in [tags] {
    mutate {
      add_field => {
        "cause" => "%{ruleDescription}"
        "event" => "Validation error"
      }
    }
  }
}
######### Filter #########

######### Output #########
output {
  if "fail" in [tags] {
  } else {
    stdout {
      codec => rubydebug
    }
    # Send directly to local Elasticsearch
    elasticsearch {
      template => "/etc/logstash/conf.d/dcat_template.json"
      template_overwrite => true
      hosts => [ "elasticsearch:9200" ]
      index => "dcat-%{+YYYY.MM.dd}"
    }
  }
}
######### Output #########
